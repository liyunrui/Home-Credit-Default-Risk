{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/linuxbrew/.linuxbrew/opt/python/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import multiprocessing as mp # for speeding up some process\n",
    "import sys\n",
    "sys.path.append('../py_model')\n",
    "from utils import init_logging\n",
    "import logging \n",
    "from fancyimpute import MICE # for imputing\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from lightgbm import LGBMClassifier\n",
    "import multiprocessing\n",
    "CPU_USE_RATE = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use prediction of model as target of test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df (356251, 280)\n",
      "72 208\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(False, True, False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# base features\n",
    "df = pd.read_hdf('../features/base_featurs.h5','base_featurs')\n",
    "copy_for_the_following_merge = df[['SK_ID_CURR','TARGET']].copy()\n",
    "no_need_to_inpute = ['index']\n",
    "df.drop(no_need_to_inpute, axis = 1, inplace = True)\n",
    "print ('df', df.shape)\n",
    "# find discrete features\n",
    "discrete_features = []\n",
    "continuous_features = []\n",
    "for f in df.columns.tolist()[:]:\n",
    "    if df[f].value_counts().size < 20:\n",
    "        discrete_features.append(f)\n",
    "    else:\n",
    "        continuous_features.append(f)\n",
    "print (len(discrete_features), len(continuous_features))\n",
    "# check \n",
    "'SK_ID_CURR' in discrete_features, 'TARGET' in discrete_features, 'index' in discrete_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df (356251, 280)\n",
      "train (307507, 280)\n",
      "test (48744, 280)\n",
      "oof_preds (307507,)\n",
      "train_preds (307507,)\n",
      "sub_preds (48744,)\n",
      "n_fold 0\n",
      "train_x (246005, 278)\n",
      "valid_x (61502, 278)\n",
      "ratio 11.386958710976838\n",
      "[1]\ttraining's auc: 0.672293\tvalid_1's auc: 0.653532\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[2]\ttraining's auc: 0.701891\tvalid_1's auc: 0.684422\n",
      "[3]\ttraining's auc: 0.728071\tvalid_1's auc: 0.712192\n",
      "[4]\ttraining's auc: 0.728205\tvalid_1's auc: 0.712139\n",
      "[5]\ttraining's auc: 0.729762\tvalid_1's auc: 0.713373\n",
      "[6]\ttraining's auc: 0.748467\tvalid_1's auc: 0.733076\n",
      "[7]\ttraining's auc: 0.752449\tvalid_1's auc: 0.737155\n",
      "[8]\ttraining's auc: 0.758733\tvalid_1's auc: 0.744268\n",
      "[9]\ttraining's auc: 0.76059\tvalid_1's auc: 0.746014\n",
      "[10]\ttraining's auc: 0.763299\tvalid_1's auc: 0.74903\n",
      "[11]\ttraining's auc: 0.766077\tvalid_1's auc: 0.751657\n",
      "[12]\ttraining's auc: 0.766842\tvalid_1's auc: 0.752548\n",
      "[13]\ttraining's auc: 0.767968\tvalid_1's auc: 0.75298\n",
      "[14]\ttraining's auc: 0.768866\tvalid_1's auc: 0.753749\n",
      "[15]\ttraining's auc: 0.769749\tvalid_1's auc: 0.754255\n",
      "[16]\ttraining's auc: 0.770577\tvalid_1's auc: 0.754734\n",
      "[17]\ttraining's auc: 0.770526\tvalid_1's auc: 0.754657\n",
      "[18]\ttraining's auc: 0.770978\tvalid_1's auc: 0.754947\n",
      "[19]\ttraining's auc: 0.771447\tvalid_1's auc: 0.755596\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-6e2d2d99d5ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m#----------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], \n\u001b[0;32m---> 60\u001b[0;31m         eval_metric= 'auc', verbose= True, early_stopping_rounds= 100) # early_stopping_rounds= 100\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0;31m# training/validating\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mprobas_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_iteration_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    693\u001b[0m                                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m                                         \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m                                         callbacks=callbacks)\n\u001b[0m\u001b[1;32m    696\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    472\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    202\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1526\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1527\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1528\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1529\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from operator import itemgetter\n",
    "\n",
    "# setting\n",
    "CPU_USE_RATE = 0.7\n",
    "num_folds = 5\n",
    "# input\n",
    "#df = df[discrete_features]\n",
    "print ('df',df.shape)\n",
    "train_df = df[df['TARGET'].notnull()]\n",
    "print ('train', train_df.shape)\n",
    "test_df = df[df['TARGET'].isnull()]\n",
    "print ('test', test_df.shape)\n",
    "# output\n",
    "oof_preds = np.zeros(train_df.shape[0]) # substitue the target of training part in df\n",
    "print ('oof_preds', oof_preds.shape)\n",
    "train_preds = np.zeros(train_df.shape[0])\n",
    "print ('train_preds', train_preds.shape)\n",
    "# test\n",
    "sub_preds = np.zeros(test_df.shape[0]) # substitue the target of testing part in df\n",
    "print ('sub_preds', sub_preds.shape)\n",
    "feats = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n",
    "# data peeking\n",
    "folds = StratifiedKFold(n_splits= num_folds, shuffle=True, random_state=int(time.time()))\n",
    "for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n",
    "    s = time.time()\n",
    "    print ('n_fold', n_fold)\n",
    "    train_x, train_y = train_df[feats].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n",
    "    print ('train_x',train_x.shape)\n",
    "    #print ('train_idx',train_idx)\n",
    "    valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df['TARGET'].iloc[valid_idx]\n",
    "    print ('valid_x',valid_x.shape)\n",
    "    #print ('valid_idx',valid_idx)\n",
    "    ratio = pd.Series(train_y).value_counts().iloc[0] / pd.Series(train_y).value_counts().iloc[1] # > 1\n",
    "    print ('ratio', ratio)\n",
    "    #----------------\n",
    "    # model \n",
    "    #----------------\n",
    "    clf = LGBMClassifier(\n",
    "        nthread=int(multiprocessing.cpu_count()*CPU_USE_RATE),\n",
    "        n_estimators=1,\n",
    "        learning_rate=0.02,\n",
    "        num_leaves=34, # 20\n",
    "        colsample_bytree=0.2, #0.9497036 < 0.2\n",
    "        subsample=0.8715623,\n",
    "        max_depth=8, # 7\n",
    "        reg_alpha=0.041545473, # 0.3\n",
    "        reg_lambda=0.0735294,\n",
    "        min_split_gain=0.0222415,\n",
    "        min_child_weight=39.3259775, # 60\n",
    "        silent=-1,\n",
    "        verbose=-1,\n",
    "        scale_pos_weight = ratio,\n",
    "        random_state = int(time.time()),\n",
    "        )\n",
    "    #----------------\n",
    "    # training \n",
    "    #----------------\n",
    "    clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], \n",
    "        eval_metric= 'auc', verbose= True, early_stopping_rounds= 1) # early_stopping_rounds= 100\n",
    "    # training/validating\n",
    "    probas_ = clf.predict_proba(valid_x, num_iteration=clf.best_iteration_)[:, 1]\n",
    "    print ('probas_', probas_)\n",
    "    fpr, tpr, thresholds = roc_curve(valid_y, probas_)\n",
    "    exp = []\n",
    "    for th in thresholds:\n",
    "        y_scores = [1 if p_ >= th else 0 for p_ in probas_]\n",
    "        exp.append((th, roc_auc_score(valid_y, y_scores)))\n",
    "    best_th = max(exp, key = itemgetter(1))[0]\n",
    "    best_performance = max(exp, key = itemgetter(1))[1]\n",
    "    print ('best_th', best_th)\n",
    "    print ('best_auc', best_performance) # 0.613309518754671\n",
    "    oof_preds[valid_idx] = [1 if p_ >= best_th else 0 for p_ in probas_]\n",
    "    print ('oof_preds', pd.Series(oof_preds[valid_idx]).value_counts()) \n",
    "    # testing\n",
    "    test_prob_ = clf.predict_proba(test_df[feats], num_iteration=clf.best_iteration_)[:, 1]\n",
    "    sub_preds +=  np.array([1 if p_ >= best_th else 0 for p_ in test_prob_])/ folds.n_splits\n",
    "    e = time.time()\n",
    "    print (e - s)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(oof_preds).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(sub_preds).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([1 if i >= 0.5 else 0 for i in sub_preds]).value_counts() # [0:0, 1/5:0, 2/5:0, 3/5: 1,..]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge and output for imputing\n",
    "copy_for_the_following_merge.TARGET.value_counts().iloc[0] / copy_for_the_following_merge.TARGET.value_counts().iloc[1]\n",
    "\n",
    "# step1: target = oof_preds + sub_preds\n",
    "# step2: 把他concate with df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_preds = np.zeros(train_df.shape[0]) # substitue the target of training part in df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_preds[[1,2,3]] =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
