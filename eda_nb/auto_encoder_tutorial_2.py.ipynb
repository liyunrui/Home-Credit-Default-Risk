{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linuxbrew/.linuxbrew/opt/python/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Tutorial on how to create an autoencoder w/ Tensorflow.\n",
    "Parag K. Mital, Jan 2016\n",
    "\"\"\"\n",
    "# %% Imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "# %% Autoencoder definition\n",
    "def autoencoder(dimensions=[784, 512, 256, 64]):\n",
    "    \"\"\"\n",
    "    Build a deep autoencoder w/ tied weights. w = wT\n",
    "    return a dict.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dimensions : list, optional\n",
    "        The number of neurons for each layer of the autoencoder.\n",
    "    Returns\n",
    "    -------\n",
    "    x : Tensor\n",
    "        Input placeholder to the network\n",
    "    z : Tensor\n",
    "        Inner-most latent representation\n",
    "    y : Tensor\n",
    "        Output reconstruction of the input\n",
    "    cost : Tensor\n",
    "        Overall cost to use for training\n",
    "    \"\"\"\n",
    "    # %% input to the network\n",
    "    x = tf.placeholder(tf.float32, [None, dimensions[0]], name='x')\n",
    "    current_input = x\n",
    "    print ('current_input', current_input.shape)\n",
    "    # %% Build the encoder\n",
    "    encoder = [] # for putting the weight of encoder, w1,w2,..\n",
    "    for layer_i, n_output in enumerate(dimensions[1:]):\n",
    "        print ('layer_i-encoder', layer_i)\n",
    "        print ('n_output-encoder', n_output)\n",
    "        n_input = int(current_input.get_shape()[1]) # [0]: batch_szie, [1]:input_dim\n",
    "        print ('n_input', n_input)\n",
    "        W = tf.Variable(\n",
    "            tf.random_uniform([n_input, n_output],\n",
    "                              minval = -1.0 / math.sqrt(n_input),\n",
    "                              maxval = 1.0 / math.sqrt(n_input)))\n",
    "        b = tf.Variable(tf.zeros([n_output]))\n",
    "        # saving layer of encoding for decoder\n",
    "        encoder.append(W)\n",
    "        output = tf.nn.tanh(tf.matmul(current_input, W) + b)\n",
    "        # assign current_input\n",
    "        current_input = output\n",
    "\n",
    "    # %% latent representation (output of encoder)\n",
    "    z = current_input\n",
    "    encoder.reverse() # [...,w2,w1]\n",
    "\n",
    "    # %% Build the decoder using the same weights\n",
    "    for layer_i, n_output in enumerate(dimensions[:-1][::-1]):\n",
    "        print ('layer_i-decoder', layer_i)\n",
    "        print ('n_output-decoder', n_output)\n",
    "        W = tf.transpose(encoder[layer_i])\n",
    "        b = tf.Variable(tf.zeros([n_output]))\n",
    "        output = tf.nn.tanh(tf.matmul(current_input, W) + b)\n",
    "        # assign current_input\n",
    "        current_input = output\n",
    "\n",
    "    # %% now have the reconstruction through the network\n",
    "    y = current_input\n",
    "\n",
    "    # %% cost function measures pixel-wise difference\n",
    "    cost = tf.reduce_sum(tf.square(y - x)) # constrution loss\n",
    "    return {'x': x, 'z': z, 'y': y, 'cost': cost}\n",
    "\n",
    "\n",
    "# %% Basic test\n",
    "def test_mnist():\n",
    "    \"\"\"Test the autoencoder using MNIST.\"\"\"\n",
    "    import tensorflow as tf\n",
    "    import tensorflow.examples.tutorials.mnist.input_data as input_data\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # %%\n",
    "    # load MNIST as before\n",
    "    mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "    # why?\n",
    "    mean_img = np.mean(mnist.train.images, axis=0)\n",
    "    print ('mean_img', mean_img.shape)\n",
    "    ae = autoencoder(dimensions=[784, 256, 64])\n",
    "\n",
    "    # %%\n",
    "    learning_rate = 0.001\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(ae['cost']) # ae['cost']: tf.placerholder\n",
    "\n",
    "    # %%\n",
    "    # We create a session to use the graph\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # %%\n",
    "    # Fit all training data\n",
    "    batch_size = 50\n",
    "    n_epochs = 10\n",
    "    for epoch_i in range(n_epochs):\n",
    "        print ('num_samples : ', mnist.train.num_examples)\n",
    "        for batch_i in range(mnist.train.num_examples // batch_size):\n",
    "            batch_xs, _ = mnist.train.next_batch(batch_size) # (50, 784)\n",
    "            #print ('batch_xs', batch_xs.shape)\n",
    "            # the below like normalization\n",
    "            train = np.array([img - mean_img for img in batch_xs])\n",
    "            #print ('train', train.shape)\n",
    "            # train\n",
    "            sess.run(optimizer, feed_dict={ae['x']: train})\n",
    "        print ('epoch_i', epoch_i)\n",
    "        print('cost', sess.run(ae['cost'], feed_dict={ae['x']: train})) # feed_dict = {tf.placeholder: real_data}\n",
    "\n",
    "    # %%\n",
    "    # Plot example reconstructions\n",
    "    n_examples = 15\n",
    "    test_xs, _ = mnist.test.next_batch(n_examples)\n",
    "    test_xs_norm = np.array([img - mean_img for img in test_xs])\n",
    "    # resconstruct --->y\n",
    "    recon = sess.run(ae['y'], feed_dict={ae['x']: test_xs_norm})\n",
    "    print ('recon',recon)\n",
    "    #fig, axs = plt.subplots(2, n_examples, figsize=(10, 2))\n",
    "    print ('n_examples', n_examples.shape)\n",
    "    for example_i in range(n_examples):\n",
    "        axs[0][example_i].imshow(\n",
    "            np.reshape(test_xs[example_i, :], (28, 28)))\n",
    "        axs[1][example_i].imshow(\n",
    "            np.reshape([recon[example_i, :] + mean_img], (28, 28)))\n",
    "#     fig.show()\n",
    "#     plt.draw()\n",
    "#     plt.waitforbuttonpress()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "mean_img (784,)\n",
      "current_input (?, 784)\n",
      "layer_i-encoder 0\n",
      "n_output-encoder 256\n",
      "n_input 784\n",
      "layer_i-encoder 1\n",
      "n_output-encoder 64\n",
      "n_input 256\n",
      "layer_i-decoder 0\n",
      "n_output-decoder 256\n",
      "layer_i-decoder 1\n",
      "n_output-decoder 784\n",
      "num_samples :  55000\n",
      "epoch_i 0\n",
      "cost 451.73486\n",
      "num_samples :  55000\n",
      "epoch_i 1\n",
      "cost 428.62915\n",
      "num_samples :  55000\n",
      "epoch_i 2\n",
      "cost 416.38776\n",
      "num_samples :  55000\n",
      "epoch_i 3\n",
      "cost 430.29376\n",
      "num_samples :  55000\n",
      "epoch_i 4\n",
      "cost 433.11243\n",
      "num_samples :  55000\n",
      "epoch_i 5\n",
      "cost 382.50592\n",
      "num_samples :  55000\n",
      "epoch_i 6\n",
      "cost 423.29608\n",
      "num_samples :  55000\n",
      "epoch_i 7\n",
      "cost 391.61313\n",
      "num_samples :  55000\n",
      "epoch_i 8\n",
      "cost 390.31744\n",
      "num_samples :  55000\n",
      "epoch_i 9\n",
      "cost 374.72513\n",
      "recon [[ 3.7915152e-03  3.0337158e-04 -5.7011534e-04 ... -3.9455949e-04\n",
      "  -2.2623525e-03 -2.9706312e-03]\n",
      " [ 5.4189313e-04  3.4965109e-05 -1.0489792e-03 ... -1.2337725e-03\n",
      "   1.5380941e-03 -7.7929691e-04]\n",
      " [ 4.4322722e-03  2.9779098e-03 -4.2425582e-04 ...  1.2782577e-05\n",
      "  -2.2268837e-04 -2.3471552e-04]\n",
      " ...\n",
      " [-2.1110752e-03 -1.1157531e-03  1.8411907e-03 ...  1.1058825e-03\n",
      "   1.8397334e-03  1.2148856e-03]\n",
      " [-6.4245192e-05 -6.9599366e-05 -8.0593833e-04 ... -6.7391997e-04\n",
      "  -9.0882444e-04 -1.6400863e-03]\n",
      " [-1.6344823e-03 -1.5343311e-03  9.1144769e-04 ... -2.1288695e-05\n",
      "   1.0386080e-03  2.7548750e-03]]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-95e39ef0f55c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# %%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtest_mnist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-3f8be7da05ae>\u001b[0m in \u001b[0;36mtest_mnist\u001b[0;34m()\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'recon'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrecon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;31m#fig, axs = plt.subplots(2, n_examples, figsize=(10, 2))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'n_examples'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_examples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mexample_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_examples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         axs[0][example_i].imshow(\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "if __name__ == '__main__':\n",
    "    test_mnist()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.random_uniform(shape, minval=0, maxval=None) : Outputs random values from a uniform distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c =  tf.random_uniform([1,2],minval = -1, maxval = 1)\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "c = sess.run(c)\n",
    "print (c, c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [1, 2]\n",
    "t.reverse()\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions=[784, 256, 64]\n",
    "dimensions[:-1][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
