{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from kmodes.kmodes import KModes\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import multiprocessing as mp # for speeding up some process\n",
    "import sys\n",
    "sys.path.append('../py_model')\n",
    "from utils import init_logging\n",
    "import logging \n",
    "from scipy.cluster import hierarchy\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams['figure.figsize'] = [16, 10] # customizing\n",
    "from ycimpute.imputer.knnimput import KNN # inputation library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356251, 279)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# base features\n",
    "df = pd.read_hdf('../features/base_featurs.h5','base_featurs')\n",
    "copy_for_the_following_merge = df[['SK_ID_CURR','TARGET']].copy()\n",
    "no_need_to_inpute = ['index', 'TARGET']\n",
    "df.drop(no_need_to_inpute, axis = 1, inplace = True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71, 208)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discrete_features = []\n",
    "continuous_features = []\n",
    "for f in df.columns.tolist()[:]:\n",
    "    if df[f].value_counts().size < 20:\n",
    "        discrete_features.append(f)\n",
    "    else:\n",
    "        continuous_features.append(f)\n",
    "len(discrete_features), len(continuous_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False, False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'SK_ID_CURR' in discrete_features, 'TARGET' in discrete_features, 'index' in discrete_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../features/peeking_target_for_imputing_w_validating_0.61231807923718_auc.csv')\n",
    "df.drop(['Unnamed: 0'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'TARGET' in df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_missing (356251, 72)\n",
      "[MICE] Completing matrix with shape (356251, 72)\n",
      "[MICE] Starting imputation round 1/110, elapsed time 0.312\n",
      "[MICE] Starting imputation round 2/110, elapsed time 13.317\n",
      "[MICE] Starting imputation round 3/110, elapsed time 25.788\n",
      "[MICE] Starting imputation round 4/110, elapsed time 38.973\n",
      "[MICE] Starting imputation round 5/110, elapsed time 52.285\n",
      "[MICE] Starting imputation round 6/110, elapsed time 65.201\n",
      "[MICE] Starting imputation round 7/110, elapsed time 78.365\n",
      "[MICE] Starting imputation round 8/110, elapsed time 91.587\n",
      "[MICE] Starting imputation round 9/110, elapsed time 105.155\n",
      "[MICE] Starting imputation round 10/110, elapsed time 118.540\n",
      "[MICE] Starting imputation round 11/110, elapsed time 131.810\n",
      "[MICE] Starting imputation round 12/110, elapsed time 145.321\n",
      "[MICE] Starting imputation round 13/110, elapsed time 158.463\n",
      "[MICE] Starting imputation round 14/110, elapsed time 171.853\n",
      "[MICE] Starting imputation round 15/110, elapsed time 185.406\n",
      "[MICE] Starting imputation round 16/110, elapsed time 198.849\n",
      "[MICE] Starting imputation round 17/110, elapsed time 212.171\n",
      "[MICE] Starting imputation round 18/110, elapsed time 225.639\n",
      "[MICE] Starting imputation round 19/110, elapsed time 238.968\n",
      "[MICE] Starting imputation round 20/110, elapsed time 252.468\n",
      "[MICE] Starting imputation round 21/110, elapsed time 265.834\n",
      "[MICE] Starting imputation round 22/110, elapsed time 279.260\n",
      "[MICE] Starting imputation round 23/110, elapsed time 292.633\n",
      "[MICE] Starting imputation round 24/110, elapsed time 305.805\n",
      "[MICE] Starting imputation round 25/110, elapsed time 319.265\n",
      "[MICE] Starting imputation round 26/110, elapsed time 332.643\n",
      "[MICE] Starting imputation round 27/110, elapsed time 345.864\n",
      "[MICE] Starting imputation round 28/110, elapsed time 359.597\n",
      "[MICE] Starting imputation round 29/110, elapsed time 371.862\n",
      "[MICE] Starting imputation round 30/110, elapsed time 385.519\n",
      "[MICE] Starting imputation round 31/110, elapsed time 398.988\n",
      "[MICE] Starting imputation round 32/110, elapsed time 412.296\n",
      "[MICE] Starting imputation round 33/110, elapsed time 425.350\n",
      "[MICE] Starting imputation round 34/110, elapsed time 438.604\n",
      "[MICE] Starting imputation round 35/110, elapsed time 451.804\n",
      "[MICE] Starting imputation round 36/110, elapsed time 465.247\n",
      "[MICE] Starting imputation round 37/110, elapsed time 478.625\n",
      "[MICE] Starting imputation round 38/110, elapsed time 491.982\n",
      "[MICE] Starting imputation round 39/110, elapsed time 505.867\n",
      "[MICE] Starting imputation round 40/110, elapsed time 518.264\n",
      "[MICE] Starting imputation round 41/110, elapsed time 531.514\n",
      "[MICE] Starting imputation round 42/110, elapsed time 544.862\n",
      "[MICE] Starting imputation round 43/110, elapsed time 558.130\n",
      "[MICE] Starting imputation round 44/110, elapsed time 571.508\n",
      "[MICE] Starting imputation round 45/110, elapsed time 584.677\n",
      "[MICE] Starting imputation round 46/110, elapsed time 598.280\n",
      "[MICE] Starting imputation round 47/110, elapsed time 611.783\n",
      "[MICE] Starting imputation round 48/110, elapsed time 624.926\n",
      "[MICE] Starting imputation round 49/110, elapsed time 638.393\n",
      "[MICE] Starting imputation round 50/110, elapsed time 651.631\n",
      "[MICE] Starting imputation round 51/110, elapsed time 664.951\n",
      "[MICE] Starting imputation round 52/110, elapsed time 678.358\n",
      "[MICE] Starting imputation round 53/110, elapsed time 691.833\n",
      "[MICE] Starting imputation round 54/110, elapsed time 705.239\n",
      "[MICE] Starting imputation round 55/110, elapsed time 718.702\n",
      "[MICE] Starting imputation round 56/110, elapsed time 732.111\n",
      "[MICE] Starting imputation round 57/110, elapsed time 745.593\n",
      "[MICE] Starting imputation round 58/110, elapsed time 759.065\n",
      "[MICE] Starting imputation round 59/110, elapsed time 772.219\n",
      "[MICE] Starting imputation round 60/110, elapsed time 786.020\n",
      "[MICE] Starting imputation round 61/110, elapsed time 798.557\n",
      "[MICE] Starting imputation round 62/110, elapsed time 811.775\n",
      "[MICE] Starting imputation round 63/110, elapsed time 825.141\n",
      "[MICE] Starting imputation round 64/110, elapsed time 838.556\n",
      "[MICE] Starting imputation round 65/110, elapsed time 851.849\n",
      "[MICE] Starting imputation round 66/110, elapsed time 864.908\n",
      "[MICE] Starting imputation round 67/110, elapsed time 878.243\n",
      "[MICE] Starting imputation round 68/110, elapsed time 891.911\n",
      "[MICE] Starting imputation round 69/110, elapsed time 905.152\n",
      "[MICE] Starting imputation round 70/110, elapsed time 917.676\n",
      "[MICE] Starting imputation round 71/110, elapsed time 931.135\n",
      "[MICE] Starting imputation round 72/110, elapsed time 944.646\n",
      "[MICE] Starting imputation round 73/110, elapsed time 958.193\n",
      "[MICE] Starting imputation round 74/110, elapsed time 971.915\n",
      "[MICE] Starting imputation round 75/110, elapsed time 985.401\n",
      "[MICE] Starting imputation round 76/110, elapsed time 998.510\n",
      "[MICE] Starting imputation round 77/110, elapsed time 1012.158\n",
      "[MICE] Starting imputation round 78/110, elapsed time 1025.333\n",
      "[MICE] Starting imputation round 79/110, elapsed time 1038.441\n",
      "[MICE] Starting imputation round 80/110, elapsed time 1052.364\n",
      "[MICE] Starting imputation round 81/110, elapsed time 1064.856\n",
      "[MICE] Starting imputation round 82/110, elapsed time 1078.186\n",
      "[MICE] Starting imputation round 83/110, elapsed time 1091.560\n",
      "[MICE] Starting imputation round 84/110, elapsed time 1104.956\n",
      "[MICE] Starting imputation round 85/110, elapsed time 1118.298\n",
      "[MICE] Starting imputation round 86/110, elapsed time 1131.343\n",
      "[MICE] Starting imputation round 87/110, elapsed time 1144.922\n",
      "[MICE] Starting imputation round 88/110, elapsed time 1159.479\n",
      "[MICE] Starting imputation round 89/110, elapsed time 1174.064\n",
      "[MICE] Starting imputation round 90/110, elapsed time 1188.622\n",
      "[MICE] Starting imputation round 91/110, elapsed time 1203.590\n",
      "[MICE] Starting imputation round 92/110, elapsed time 1219.769\n",
      "[MICE] Starting imputation round 93/110, elapsed time 1235.483\n",
      "[MICE] Starting imputation round 94/110, elapsed time 1251.505\n",
      "[MICE] Starting imputation round 95/110, elapsed time 1267.432\n",
      "[MICE] Starting imputation round 96/110, elapsed time 1283.756\n",
      "[MICE] Starting imputation round 97/110, elapsed time 1299.646\n",
      "[MICE] Starting imputation round 98/110, elapsed time 1315.549\n",
      "[MICE] Starting imputation round 99/110, elapsed time 1331.445\n",
      "[MICE] Starting imputation round 100/110, elapsed time 1347.157\n",
      "[MICE] Starting imputation round 101/110, elapsed time 1363.509\n",
      "[MICE] Starting imputation round 102/110, elapsed time 1379.318\n",
      "[MICE] Starting imputation round 103/110, elapsed time 1395.356\n",
      "[MICE] Starting imputation round 104/110, elapsed time 1411.478\n",
      "[MICE] Starting imputation round 105/110, elapsed time 1428.214\n",
      "[MICE] Starting imputation round 106/110, elapsed time 1443.689\n",
      "[MICE] Starting imputation round 107/110, elapsed time 1458.956\n",
      "[MICE] Starting imputation round 108/110, elapsed time 1473.831\n",
      "[MICE] Starting imputation round 109/110, elapsed time 1489.212\n",
      "[MICE] Starting imputation round 110/110, elapsed time 1505.258\n"
     ]
    }
   ],
   "source": [
    "X_missing = df.copy()\n",
    "# feature scaling before KNN\n",
    "feature_scaling = True\n",
    "if feature_scaling == True:\n",
    "    for f in X_missing.columns.tolist():\n",
    "        mean = X_missing[f].mean()\n",
    "        std = X_missing[f].std()\n",
    "        X_missing[f] = (X_missing[f] - mean) / std\n",
    "\n",
    "print ('X_missing', X_missing.shape)\n",
    "    \n",
    "#-------------------\n",
    "# core algorithm: input should be array\n",
    "#-------------------\n",
    "from fancyimpute import MICE # for imputing\n",
    "\n",
    "logging.info('visit_sequence: {}'.format('monotone')) \n",
    "logging.info('impute_type: {}'.format('col')) \n",
    "logging.info('init_fill_method: {}'.format('mean')) \n",
    "logging.info('target == 1')\n",
    "X_filled = MICE(visit_sequence = 'monotone', \n",
    "                impute_type = 'col',\n",
    "                init_fill_method = 'mean').complete(X_missing.values)\n",
    "X_filled = pd.DataFrame(X_filled, columns = X_missing.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featurs AMT_REQ_CREDIT_BUREAU_QRT\n",
      "featurs CODE_GENDER\n",
      "featurs DEF_30_CNT_SOCIAL_CIRCLE\n",
      "featurs DEF_60_CNT_SOCIAL_CIRCLE\n",
      "featurs FLAG_DOCUMENT_11\n",
      "featurs FLAG_DOCUMENT_18\n",
      "featurs FLAG_DOCUMENT_3\n",
      "featurs FLAG_DOCUMENT_8\n",
      "featurs FLAG_OWN_CAR\n",
      "featurs FLAG_PHONE\n",
      "featurs FLAG_WORK_PHONE\n",
      "featurs LIVE_CITY_NOT_WORK_CITY\n",
      "featurs REGION_RATING_CLIENT\n",
      "featurs REGION_RATING_CLIENT_W_CITY\n",
      "featurs REG_CITY_NOT_LIVE_CITY\n",
      "featurs TARGET\n",
      "featurs NEW_DOC_IND_STD\n",
      "featurs NEW_DOC_IND_KURT\n",
      "featurs AMT_INCOME_TOTAL_BY_CODE_GENDER_NAME_EDUCATION_TYPE\n",
      "featurs AMT_ANNUITY_BY_OCCUPATION_TYPE\n",
      "featurs CNT_CHILDREN_BY_OCCUPATION_TYPE\n",
      "featurs CNT_FAM_MEMBERS_BY_OCCUPATION_TYPE\n",
      "featurs DAYS_BIRTH_BY_OCCUPATION_TYPE\n",
      "featurs DAYS_EMPLOYED_BY_OCCUPATION_TYPE\n",
      "featurs DAYS_ID_PUBLISH_BY_OCCUPATION_TYPE\n",
      "featurs DAYS_REGISTRATION_BY_OCCUPATION_TYPE\n",
      "featurs EXT_SOURCE_1_BY_OCCUPATION_TYPE\n",
      "featurs EXT_SOURCE_2_BY_OCCUPATION_TYPE\n",
      "featurs EXT_SOURCE_3_BY_OCCUPATION_TYPE\n",
      "featurs NAME_CONTRACT_TYPE_Cash loans\n",
      "featurs NAME_CONTRACT_TYPE_Revolving loans\n",
      "featurs NAME_EDUCATION_TYPE_Higher education\n",
      "featurs NAME_EDUCATION_TYPE_Lower secondary\n",
      "featurs NAME_EDUCATION_TYPE_Secondary / secondary special\n",
      "featurs NAME_FAMILY_STATUS_Married\n",
      "featurs NAME_FAMILY_STATUS_Single / not married\n",
      "featurs NAME_HOUSING_TYPE_House / apartment\n",
      "featurs NAME_HOUSING_TYPE_Municipal apartment\n",
      "featurs NAME_HOUSING_TYPE_Office apartment\n",
      "featurs NAME_INCOME_TYPE_State servant\n",
      "featurs NAME_INCOME_TYPE_Working\n",
      "featurs NAME_TYPE_SUITE_Other_B\n",
      "featurs OCCUPATION_TYPE_Accountants\n",
      "featurs OCCUPATION_TYPE_Core staff\n",
      "featurs OCCUPATION_TYPE_Drivers\n",
      "featurs OCCUPATION_TYPE_High skill tech staff\n",
      "featurs OCCUPATION_TYPE_Laborers\n",
      "featurs OCCUPATION_TYPE_Low-skill Laborers\n",
      "featurs OCCUPATION_TYPE_Medicine staff\n",
      "featurs OCCUPATION_TYPE_Sales staff\n",
      "featurs ORGANIZATION_TYPE_Bank\n",
      "featurs ORGANIZATION_TYPE_Business Entity Type 3\n",
      "featurs ORGANIZATION_TYPE_Construction\n",
      "featurs ORGANIZATION_TYPE_Hotel\n",
      "featurs ORGANIZATION_TYPE_Industry: type 9\n",
      "featurs ORGANIZATION_TYPE_Kindergarten\n",
      "featurs ORGANIZATION_TYPE_Medicine\n",
      "featurs ORGANIZATION_TYPE_Military\n",
      "featurs ORGANIZATION_TYPE_Police\n",
      "featurs ORGANIZATION_TYPE_Restaurant\n",
      "featurs ORGANIZATION_TYPE_School\n",
      "featurs ORGANIZATION_TYPE_Security Ministries\n",
      "featurs ORGANIZATION_TYPE_Self-employed\n",
      "featurs ORGANIZATION_TYPE_Transport: type 3\n",
      "featurs WALLSMATERIAL_MODE_Others\n",
      "featurs WALLSMATERIAL_MODE_Panel\n",
      "featurs WALLSMATERIAL_MODE_Stone, brick\n",
      "featurs WEEKDAY_APPR_PROCESS_START_MONDAY\n",
      "featurs WEEKDAY_APPR_PROCESS_START_SUNDAY\n",
      "featurs WEEKDAY_APPR_PROCESS_START_TUESDAY\n",
      "featurs WEEKDAY_APPR_PROCESS_START_WEDNESDAY\n",
      "featurs CC_NAME_CONTRACT_STATUS_Active_MIN\n",
      "(356251, 280)\n"
     ]
    }
   ],
   "source": [
    "# base features\n",
    "df = pd.read_hdf('../features/base_featurs.h5','base_featurs')\n",
    "copy_for_the_following_merge = df[['SK_ID_CURR','TARGET']].copy()\n",
    "no_need_to_inpute = ['index', 'TARGET']\n",
    "df.drop(no_need_to_inpute, axis = 1, inplace = True)\n",
    "\n",
    "for f_in_same_cluster in X_filled.columns.tolist():\n",
    "    print ('featurs', f_in_same_cluster)\n",
    "    df[f_in_same_cluster] = X_filled[f_in_same_cluster]\n",
    "print (df.shape)\n",
    "# if 'TARGET' in df.columns.tolist():\n",
    "#     df.drop(['TARGET'], axis = 1, inplace = True)\n",
    "\n",
    "# df = pd.merge(df, copy_for_the_following_merge, on = 'SK_ID_CURR', how = 'left')\n",
    "# print ('final', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'TARGET' in df.columns.tolist(), 'SK_ID_CURR' in df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final (356251, 280)\n"
     ]
    }
   ],
   "source": [
    "if 'TARGET' in df.columns.tolist():\n",
    "    df.drop(['TARGET'], axis = 1, inplace = True)\n",
    "\n",
    "df = pd.merge(df, copy_for_the_following_merge, on = 'SK_ID_CURR', how = 'left')\n",
    "print ('final', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------\n",
    "# save\n",
    "#-------------------\n",
    "output_path = '../features/filled_by_mice'\n",
    "if not os.path.isdir(output_path):\n",
    "    os.mkdir(output_path)\n",
    "\n",
    "df.to_hdf(\n",
    "    os.path.join(output_path, 'normalized_mice_discrete_w_peeking_target_612.h5'), \n",
    "    'normalized_mice_discrete_w_peeking_target_612')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['base_featurs_filled_mice_by_cluster_2+1.h5',\n",
       " 'normalized_mice_discrete_wo_target.h5',\n",
       " 'normalized_mice_discrete_w_peeking_target_724.h5',\n",
       " 'normalized_mice_discrete.h5',\n",
       " 'normalized_mice_similar_features_th_09_5.h5',\n",
       " 'normalized_mice_cluster_3.h5',\n",
       " 'base_featurs_filled_mice_by_cluster_2.h5',\n",
       " 'normalized_mice_discrete_w_peeking_target.h5',\n",
       " '.DS_Store',\n",
       " 'base_featurs_filled_mice_clustering.h5',\n",
       " 'base_featurs_filled_mice_by_cluster_1.h5',\n",
       " 'normalized_mice_cluster_1_2_3.h5',\n",
       " 'normalized_mice_similar_features_th_09_2.h5',\n",
       " 'normalized_mice_similar_features_th_09_1.h5',\n",
       " 'normalized_mice_cluster_2.h5',\n",
       " 'base_featurs_filled_mice_half_training_data.h5',\n",
       " 'normalized_mice_cluster_1.h5',\n",
       " 'normalized_mice_discrete_w_peeking_target_612.h5',\n",
       " 'base_featurs_filled_mice_half_training_data_wo_target.h5']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../features/filled_by_mice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(356251, 281)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linuxbrew/.linuxbrew/opt/python/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_missing (356251, 208)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/linuxbrew/.linuxbrew/opt/python/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MICE] Completing matrix with shape (356251, 208)\n",
      "[MICE] Starting imputation round 1/110, elapsed time 1.114\n",
      "[MICE] Starting imputation round 2/110, elapsed time 336.723\n",
      "[MICE] Starting imputation round 3/110, elapsed time 676.015\n",
      "[MICE] Starting imputation round 4/110, elapsed time 1020.693\n",
      "[MICE] Starting imputation round 5/110, elapsed time 1359.937\n",
      "[MICE] Starting imputation round 6/110, elapsed time 1691.874\n",
      "[MICE] Starting imputation round 7/110, elapsed time 2023.672\n",
      "[MICE] Starting imputation round 8/110, elapsed time 2363.061\n",
      "[MICE] Starting imputation round 9/110, elapsed time 2701.611\n",
      "[MICE] Starting imputation round 10/110, elapsed time 3033.714\n",
      "[MICE] Starting imputation round 11/110, elapsed time 3366.829\n",
      "[MICE] Starting imputation round 12/110, elapsed time 3701.154\n",
      "[MICE] Starting imputation round 13/110, elapsed time 4039.028\n",
      "[MICE] Starting imputation round 14/110, elapsed time 4372.514\n",
      "[MICE] Starting imputation round 15/110, elapsed time 4708.013\n",
      "[MICE] Starting imputation round 16/110, elapsed time 5045.893\n",
      "[MICE] Starting imputation round 17/110, elapsed time 5384.531\n",
      "[MICE] Starting imputation round 18/110, elapsed time 5720.775\n",
      "[MICE] Starting imputation round 19/110, elapsed time 6056.058\n",
      "[MICE] Starting imputation round 20/110, elapsed time 6388.280\n",
      "[MICE] Starting imputation round 21/110, elapsed time 6726.574\n",
      "[MICE] Starting imputation round 22/110, elapsed time 7060.450\n",
      "[MICE] Starting imputation round 23/110, elapsed time 7397.191\n",
      "[MICE] Starting imputation round 24/110, elapsed time 7732.028\n",
      "[MICE] Starting imputation round 25/110, elapsed time 8068.327\n",
      "[MICE] Starting imputation round 26/110, elapsed time 8409.290\n",
      "[MICE] Starting imputation round 27/110, elapsed time 8744.803\n",
      "[MICE] Starting imputation round 28/110, elapsed time 9081.055\n",
      "[MICE] Starting imputation round 29/110, elapsed time 9416.365\n",
      "[MICE] Starting imputation round 30/110, elapsed time 9752.045\n",
      "[MICE] Starting imputation round 31/110, elapsed time 10091.343\n",
      "[MICE] Starting imputation round 32/110, elapsed time 10432.418\n",
      "[MICE] Starting imputation round 33/110, elapsed time 10771.286\n",
      "[MICE] Starting imputation round 34/110, elapsed time 11109.833\n",
      "[MICE] Starting imputation round 35/110, elapsed time 11445.969\n",
      "[MICE] Starting imputation round 36/110, elapsed time 11782.424\n",
      "[MICE] Starting imputation round 37/110, elapsed time 12118.989\n",
      "[MICE] Starting imputation round 38/110, elapsed time 12461.598\n",
      "[MICE] Starting imputation round 39/110, elapsed time 12803.155\n",
      "[MICE] Starting imputation round 40/110, elapsed time 13133.739\n",
      "[MICE] Starting imputation round 41/110, elapsed time 13469.917\n",
      "[MICE] Starting imputation round 42/110, elapsed time 13810.535\n",
      "[MICE] Starting imputation round 43/110, elapsed time 14146.206\n",
      "[MICE] Starting imputation round 44/110, elapsed time 14482.417\n",
      "[MICE] Starting imputation round 45/110, elapsed time 14822.483\n",
      "[MICE] Starting imputation round 46/110, elapsed time 15165.101\n",
      "[MICE] Starting imputation round 47/110, elapsed time 15505.442\n",
      "[MICE] Starting imputation round 48/110, elapsed time 15843.644\n",
      "[MICE] Starting imputation round 49/110, elapsed time 16184.069\n",
      "[MICE] Starting imputation round 50/110, elapsed time 16518.078\n",
      "[MICE] Starting imputation round 51/110, elapsed time 16856.036\n",
      "[MICE] Starting imputation round 52/110, elapsed time 17193.560\n",
      "[MICE] Starting imputation round 53/110, elapsed time 17527.475\n",
      "[MICE] Starting imputation round 54/110, elapsed time 17864.280\n",
      "[MICE] Starting imputation round 55/110, elapsed time 18201.210\n",
      "[MICE] Starting imputation round 56/110, elapsed time 18541.176\n",
      "[MICE] Starting imputation round 57/110, elapsed time 18881.076\n",
      "[MICE] Starting imputation round 58/110, elapsed time 19217.568\n"
     ]
    }
   ],
   "source": [
    "# base features\n",
    "df = pd.read_hdf('../features/base_featurs.h5','base_featurs')\n",
    "copy_for_the_following_merge = df[['SK_ID_CURR','TARGET']].copy()\n",
    "print (df.shape)\n",
    "# handling with infinity\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace = True)\n",
    "X_missing = df[continuous_features]\n",
    "\n",
    "# feature scaling before KNN\n",
    "feature_scaling = True\n",
    "if feature_scaling == True:\n",
    "    for f in X_missing.columns.tolist():\n",
    "        mean = X_missing[f].mean()\n",
    "        std = X_missing[f].std()\n",
    "        X_missing[f] = (X_missing[f] - mean) / std\n",
    "\n",
    "print ('X_missing', X_missing.shape)\n",
    "    \n",
    "#-------------------\n",
    "# core algorithm: input should be array\n",
    "#-------------------\n",
    "from fancyimpute import MICE # for imputing\n",
    "\n",
    "logging.info('visit_sequence: {}'.format('monotone')) \n",
    "logging.info('impute_type: {}'.format('col')) \n",
    "logging.info('init_fill_method: {}'.format('mean')) \n",
    "logging.info('target == 1')\n",
    "X_filled = MICE(visit_sequence = 'monotone', \n",
    "                impute_type = 'col',\n",
    "                init_fill_method = 'mean').complete(X_missing.values)\n",
    "X_filled = pd.DataFrame(X_filled, columns = X_missing.columns)\n",
    "\n",
    "for f_in_same_cluster in X_filled.columns.tolist():\n",
    "    print ('featurs', f_in_same_cluster)\n",
    "    df[f_in_same_cluster] = X_filled[f_in_same_cluster]\n",
    "\n",
    "if 'TARGET' in df.columns.tolist():\n",
    "    df.drop(['TARGET'], axis = 1, inplace = True)\n",
    "\n",
    "df = pd.merge(df, copy_for_the_following_merge, on = 'SK_ID_CURR', how = 'left')\n",
    "print ('final', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------\n",
    "# save\n",
    "#-------------------\n",
    "output_path = '../features/filled_by_mice'\n",
    "if not os.path.isdir(output_path):\n",
    "    os.mkdir(output_path)\n",
    "\n",
    "df.to_hdf(\n",
    "    os.path.join(output_path, 'normalized_mice_continue.h5'), \n",
    "    'normalized_mice_continue')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base features\n",
    "df = pd.read_hdf('../features/base_featurs.h5','base_featurs')\n",
    "print (df.shape)\n",
    "X_missing1 = df[discrete_features]\n",
    "# feature scaling before KNN\n",
    "feature_scaling = True\n",
    "if feature_scaling == True:\n",
    "    for f in X_missing1.columns.tolist():\n",
    "        mean = X_missing1[f].mean()\n",
    "        std = X_missing1[f].std()\n",
    "        X_missing1[f] = (X_missing1[f] - mean) / std\n",
    "\n",
    "print ('X_missing', X_missing1.shape)\n",
    "    \n",
    "#-------------------\n",
    "# core algorithm: input should be array\n",
    "#-------------------\n",
    "from fancyimpute import MICE # for imputing\n",
    "\n",
    "logging.info('visit_sequence: {}'.format('monotone')) \n",
    "logging.info('impute_type: {}'.format('col')) \n",
    "logging.info('init_fill_method: {}'.format('mean')) \n",
    "logging.info('target == 1')\n",
    "X_filled1 = MICE(visit_sequence = 'monotone', \n",
    "                impute_type = 'col',\n",
    "                init_fill_method = 'mean').complete(X_missing1.values)\n",
    "X_filled1 = pd.DataFrame(X_filled1, columns = X_missing1.columns)\n",
    "\n",
    "# base features\n",
    "df = pd.read_hdf('../features/base_featurs.h5','base_featurs')\n",
    "print (df.shape)\n",
    "X_missing2 = df[discrete_features]\n",
    "# feature scaling before KNN\n",
    "feature_scaling = True\n",
    "if feature_scaling == True:\n",
    "    for f in X_missing2.columns.tolist():\n",
    "        mean = X_missing2[f].mean()\n",
    "        std = X_missing2[f].std()\n",
    "        X_missing2[f] = (X_missing2[f] - mean) / std\n",
    "\n",
    "print ('X_missing', X_missing2.shape)\n",
    "    \n",
    "#-------------------\n",
    "# core algorithm: input should be array\n",
    "#-------------------\n",
    "from fancyimpute import MICE # for imputing\n",
    "\n",
    "logging.info('visit_sequence: {}'.format('monotone')) \n",
    "logging.info('impute_type: {}'.format('col')) \n",
    "logging.info('init_fill_method: {}'.format('mean')) \n",
    "logging.info('target == 1')\n",
    "X_filled2 = MICE(visit_sequence = 'monotone', \n",
    "                impute_type = 'col',\n",
    "                init_fill_method = 'mean').complete(X_missing2.values)\n",
    "X_filled2 = pd.DataFrame(X_filled2, columns = X_missing2.columns)\n",
    "\n",
    "\n",
    "for f_in_same_cluster in X_filled1.columns.tolist():\n",
    "    print ('featurs', f_in_same_cluster)\n",
    "    df[f_in_same_cluster] = X_filled1[f_in_same_cluster]\n",
    "    \n",
    "for f_in_same_cluster in X_filled2.columns.tolist():\n",
    "    print ('featurs', f_in_same_cluster)\n",
    "    df[f_in_same_cluster] = X_filled2[f_in_same_cluster]\n",
    "    \n",
    "if 'TARGET' in df.columns.tolist():\n",
    "    df.drop(['TARGET'], axis = 1, inplace = True)\n",
    "\n",
    "df = pd.merge(df, copy_for_the_following_merge, on = 'SK_ID_CURR', how = 'left')\n",
    "print ('final', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------\n",
    "# save\n",
    "#-------------------\n",
    "output_path = '../features/filled_by_mice'\n",
    "if not os.path.isdir(output_path):\n",
    "    os.mkdir(output_path)\n",
    "\n",
    "df.to_hdf(\n",
    "    os.path.join(output_path, 'normalized_mice_discrtete_continue.h5'), \n",
    "    'normalized_mice_discrtete_continue')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_scaling = True\n",
    "X_missing_df = df[discrete_features]\n",
    "# feature scaling before KNN\n",
    "if feature_scaling == True:\n",
    "    for f in X_missing_df.columns.tolist():\n",
    "        mean = X_missing_df[f].mean()\n",
    "        std = X_missing_df[f].std()\n",
    "        X_missing_df[f] = (X_missing_df[f] - mean) / std\n",
    "\n",
    "#----------------------------\n",
    "# KNN imputing\n",
    "#----------------------------\n",
    "small_df_ls = []\n",
    "previous_step = None\n",
    "num_split = 20\n",
    "for i, step in enumerate(np.arange(0, X_missing_df.shape[0], step = int(X_missing_df.shape[0] / num_split))):\n",
    "    # for memory problem, we cannot feed all the data points into algorithm, which depends on row and n_features\n",
    "    if i == 0:\n",
    "        pass\n",
    "    elif i == 1:\n",
    "        small_df_ls.append(X_missing_df[0: step])\n",
    "        previous_step = step\n",
    "    elif i == (num_split):\n",
    "        small_df_ls.append(X_missing_df[previous_step: ])\n",
    "        break\n",
    "    else:\n",
    "        small_df_ls.append(X_missing_df[previous_step: step])\n",
    "        previous_step = step\n",
    "'splitting is okay? {}'.format(pd.concat(small_df_ls, axis = 0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi(small_df):\n",
    "    X_missing = small_df.copy()\n",
    "    print ('input of KNN imputing : {}'.format(X_missing.shape))\n",
    "    # core algorithm: input should be array\n",
    "    X_filled = KNN(k = k).complete(X_missing.values)\n",
    "    return pd.DataFrame(X_filled, columns = X_missing.columns)\n",
    "mp_pool = mp.Pool(len(small_df_ls)) \n",
    "small_df_filled_ls = mp_pool.map(multi, small_df_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------\n",
    "# imputing\n",
    "#----------------------------\n",
    "k = 65\n",
    "small_df_filled_ls = []\n",
    "for small_df in small_df_ls:\n",
    "    X_missing = small_df.copy()\n",
    "    print ('input of KNN imputing : {}'.format(X_missing.shape))\n",
    "    # core algorithm: input should be array\n",
    "    X_filled = KNN(k = k).complete(X_missing.values)\n",
    "    small_df_filled_ls.append(pd.DataFrame(X_filled, columns = X_missing.columns))\n",
    "\n",
    "X_filled1 = pd.concat(small_df_filled_ls, axis = 0)\n",
    "'X_filled1 : {}'.format(X_filled1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'TARGET' in discrete_features, 'SK_ID_CURR' in discrete_features, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------\n",
    "# reload base_features for filling\n",
    "#----------------------------\n",
    "df = pd.read_hdf('../features/base_featurs.h5','base_featurs')\n",
    "copy_for_the_following_merge = df[['SK_ID_CURR','TARGET']].copy()\n",
    "no_need_to_inpute = ['index']\n",
    "df.drop(no_need_to_inpute, axis = 1, inplace = True)\n",
    "for f_in_same_cluster in X_filled1.columns.tolist():\n",
    "    if f_in_same_cluster in set(df.columns.tolist()):\n",
    "        #logging.info('featurs : {}'.format(f_in_same_cluster))\n",
    "        df[f_in_same_cluster] = X_filled1[f_in_same_cluster].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'SK_ID_CURR' in X_filled1.columns.tolist():\n",
    "    df.drop(['SK_ID_CURR'], axis = 1, inplace = True)\n",
    "if 'TARGET' in X_filled1.columns.tolist():\n",
    "    df.drop(['TARGET'], axis = 1, inplace = True)\n",
    "    \n",
    "df = pd.merge(df, copy_for_the_following_merge, on = 'SK_ID_CURR', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------\n",
    "# save\n",
    "#-------------------\n",
    "output_path = '../features/filled_by_knn'\n",
    "if not os.path.isdir(output_path):\n",
    "    os.mkdir(output_path)\n",
    "\n",
    "df.to_hdf(\n",
    "    os.path.join(output_path, 'normalized_knn_65_descrete.h5'), 'normalized_knn_65_descrete')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# continuous features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base features\n",
    "df = pd.read_hdf('../features/base_featurs.h5','base_featurs')\n",
    "print (df.shape)\n",
    "\n",
    "feature_scaling = True\n",
    "X_missing_df = df[continuous_features]\n",
    "# feature scaling before KNN\n",
    "if feature_scaling == True:\n",
    "    for f in X_missing_df.columns.tolist():\n",
    "        mean = X_missing_df[f].mean()\n",
    "        std = X_missing_df[f].std()\n",
    "        X_missing_df[f] = (X_missing_df[f] - mean) / std\n",
    "\n",
    "#----------------------------\n",
    "# KNN imputing\n",
    "#----------------------------\n",
    "small_df_ls = []\n",
    "previous_step = None\n",
    "num_split = 20\n",
    "for i, step in enumerate(np.arange(0, X_missing_df.shape[0], step = int(X_missing_df.shape[0] / num_split))):\n",
    "    # for memory problem, we cannot feed all the data points into algorithm, which depends on row and n_features\n",
    "    if i == 0:\n",
    "        pass\n",
    "    elif i == 1:\n",
    "        small_df_ls.append(X_missing_df[0: step])\n",
    "        previous_step = step\n",
    "    elif i == (num_split):\n",
    "        small_df_ls.append(X_missing_df[previous_step: ])\n",
    "        break\n",
    "    else:\n",
    "        small_df_ls.append(X_missing_df[previous_step: step])\n",
    "        previous_step = step\n",
    "'splitting is okay? {}'.format(pd.concat(small_df_ls, axis = 0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi(small_df):\n",
    "    k = 65\n",
    "    print ('input of KNN imputing : {}'.format(small_df.shape))\n",
    "    # core algorithm: input should be array\n",
    "    X_filled = KNN(k = k).complete(small_df.values)\n",
    "    return pd.DataFrame(X_filled, columns = small_df.columns)\n",
    "mp_pool = mp.Pool(len(small_df_ls)) \n",
    "small_df_filled_ls = mp_pool.map(multi, small_df_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_filled1 = pd.concat(small_df_filled_ls, axis = 0)\n",
    "'X_filled1 : {}'.format(X_filled1.shape)\n",
    "#----------------------------\n",
    "# reload base_features for filling\n",
    "#----------------------------\n",
    "df = pd.read_hdf('../features/base_featurs.h5','base_featurs')\n",
    "copy_for_the_following_merge = df[['SK_ID_CURR','TARGET']].copy()\n",
    "no_need_to_inpute = ['index']\n",
    "df.drop(no_need_to_inpute, axis = 1, inplace = True)\n",
    "for f_in_same_cluster in X_filled1.columns.tolist():\n",
    "    if f_in_same_cluster in set(df.columns.tolist()):\n",
    "        #logging.info('featurs : {}'.format(f_in_same_cluster))\n",
    "        df[f_in_same_cluster] = X_filled1[f_in_same_cluster].tolist()\n",
    "        \n",
    "if 'TARGET' in df.columns.tolist():\n",
    "    df.drop(['TARGET'], axis = 1, inplace = True)\n",
    "\n",
    "df = pd.merge(df, copy_for_the_following_merge, on = 'SK_ID_CURR', how = 'left')\n",
    "print ('final', df.shape)\n",
    "\n",
    "#-------------------\n",
    "# save\n",
    "#-------------------\n",
    "output_path = '../features/filled_by_knn'\n",
    "if not os.path.isdir(output_path):\n",
    "    os.mkdir(output_path)\n",
    "\n",
    "df.to_hdf(\n",
    "    os.path.join(output_path, 'normalized_knn_65_continue.h5'), 'normalized_knn_65_continue')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf('../features/filled_by_knn/normalized_knn_65_descrete.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356221</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356222</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356223</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356224</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356225</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356226</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356227</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356228</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356229</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356230</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356231</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356232</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356233</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356234</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356235</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356236</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356237</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356238</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356239</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356240</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356241</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356242</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356243</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356244</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356245</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356246</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356247</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356248</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356249</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356250</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>356251 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TARGET\n",
       "0          1.0\n",
       "1          0.0\n",
       "2          0.0\n",
       "3          0.0\n",
       "4          0.0\n",
       "5          0.0\n",
       "6          0.0\n",
       "7          0.0\n",
       "8          0.0\n",
       "9          0.0\n",
       "10         0.0\n",
       "11         0.0\n",
       "12         0.0\n",
       "13         0.0\n",
       "14         0.0\n",
       "15         0.0\n",
       "16         0.0\n",
       "17         0.0\n",
       "18         0.0\n",
       "19         0.0\n",
       "20         0.0\n",
       "21         0.0\n",
       "22         0.0\n",
       "23         0.0\n",
       "24         0.0\n",
       "25         0.0\n",
       "26         1.0\n",
       "27         0.0\n",
       "28         0.0\n",
       "29         0.0\n",
       "...        ...\n",
       "356221     NaN\n",
       "356222     NaN\n",
       "356223     NaN\n",
       "356224     NaN\n",
       "356225     NaN\n",
       "356226     NaN\n",
       "356227     NaN\n",
       "356228     NaN\n",
       "356229     NaN\n",
       "356230     NaN\n",
       "356231     NaN\n",
       "356232     NaN\n",
       "356233     NaN\n",
       "356234     NaN\n",
       "356235     NaN\n",
       "356236     NaN\n",
       "356237     NaN\n",
       "356238     NaN\n",
       "356239     NaN\n",
       "356240     NaN\n",
       "356241     NaN\n",
       "356242     NaN\n",
       "356243     NaN\n",
       "356244     NaN\n",
       "356245     NaN\n",
       "356246     NaN\n",
       "356247     NaN\n",
       "356248     NaN\n",
       "356249     NaN\n",
       "356250     NaN\n",
       "\n",
       "[356251 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['TARGET']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
