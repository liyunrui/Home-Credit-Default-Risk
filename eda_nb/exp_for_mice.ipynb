{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "One imputation method, 10 iterations may take 1 hrs.\n",
    "\n",
    "test_id 如果是隨機的, 會有引響麼, 理論上只要sort就好, 就算有?\n",
    "'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import multiprocessing\n",
    "import warnings\n",
    "import sys\n",
    "sys.path.append('../py_model')\n",
    "from utils import init_logging\n",
    "import logging \n",
    "import os\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "np.random.seed(int(time.time()))\n",
    "\n",
    "NUM_FOLDS = 5\n",
    "STRATIFIED = True  \n",
    "TEST_NULL_HYPO = False\n",
    "ITERATION = (80 if TEST_NULL_HYPO else 10) # It means how many iterations need to get the final stable AUC score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))\n",
    "\n",
    "# LightGBM GBDT with KFold or Stratified KFold\n",
    "# Parameters from Tilii kernel: https://www.kaggle.com/tilii7/olivier-lightgbm-parameters-by-bayesian-opt/code\n",
    "def kfold_lightgbm(df, num_folds, stratified = False):\n",
    "    '''\n",
    "    num_folds: int, how many foles u'r going to split.\n",
    "\n",
    "    Maybe we can write a helper function, to find a best parametres each time when u add a new features, to make sure reliability of experiment.\n",
    "    But, the experiement time will go up more.\n",
    "    '''\n",
    "    #---------------------\n",
    "    # Divide in training/validation and test data\n",
    "    #---------------------\n",
    "    train_df = df[df['TARGET'].notnull()]\n",
    "    test_df = df[df['TARGET'].isnull()]\n",
    "    # \n",
    "    logging.info('no bugging in split' if train_df.shape[0] + test_df.shape[0] == df.shape[0] else \" opps\")\n",
    "    #---------------------\n",
    "    # core\n",
    "    #---------------------\n",
    "    logging.info(\"Starting LightGBM. Train shape: {}, test shape: {}\".format(train_df.shape, test_df.shape))\n",
    "    del df\n",
    "    gc.collect()\n",
    "    # Cross validation model\n",
    "    if stratified:\n",
    "        folds = StratifiedKFold(n_splits= num_folds, shuffle=True, random_state=int(time.time()))\n",
    "    else:\n",
    "        folds = KFold(n_splits= num_folds, shuffle=True, random_state=int(time.time()))\n",
    "    # Create arrays and dataframes to store results\n",
    "    # train\n",
    "    oof_preds = np.zeros(train_df.shape[0])\n",
    "    train_preds = np.zeros(train_df.shape[0])\n",
    "    # test\n",
    "    sub_preds = np.zeros(test_df.shape[0])\n",
    "    # feature importance\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "\n",
    "    feats = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n",
    "    \n",
    "    if TEST_NULL_HYPO:\n",
    "        train_df['TARGET'] = train_df['TARGET'].copy().sample(frac = 1.0).values\n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n",
    "        train_x, train_y = train_df[feats].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n",
    "        valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df['TARGET'].iloc[valid_idx]\n",
    "\n",
    "        # LightGBM parameters found by Bayesian optimization\n",
    "        if TEST_NULL_HYPO:\n",
    "            clf = LGBMClassifier(\n",
    "                nthread=int(multiprocessing.cpu_count()*CPU_USE_RATE),\n",
    "                n_estimators=10000,\n",
    "                learning_rate=0.02,\n",
    "                num_leaves=127,\n",
    "                max_depth=8,\n",
    "                silent=-1,\n",
    "                verbose=-1,\n",
    "                random_state=int(time.time()),\n",
    "                )\n",
    "        else:\n",
    "            clf = LGBMClassifier(\n",
    "                nthread=int(multiprocessing.cpu_count()*CPU_USE_RATE),\n",
    "                n_estimators=10000,\n",
    "                learning_rate=0.02,\n",
    "                num_leaves=34, # 20\n",
    "                colsample_bytree=0.2, #0.9497036 < 0.2\n",
    "                subsample=0.8715623,\n",
    "                max_depth=8, # 7\n",
    "                reg_alpha=0.041545473, # 0.3\n",
    "                reg_lambda=0.0735294,\n",
    "                min_split_gain=0.0222415,\n",
    "                min_child_weight=39.3259775, # 60\n",
    "                silent=-1,\n",
    "                verbose=-1,\n",
    "                random_state=int(time.time()),\n",
    "                )\n",
    "\n",
    "        clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], \n",
    "            eval_metric= 'auc', verbose= False, early_stopping_rounds= 100) # early_stopping_rounds= 200\n",
    "        # training/validating\n",
    "        oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration=clf.best_iteration_)[:, 1]\n",
    "        train_preds[train_idx] += clf.predict_proba(train_x, num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits\n",
    "        # testing\n",
    "        sub_preds += clf.predict_proba(test_df[feats], num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits\n",
    "\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = feats\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importances_\n",
    "        fold_importance_df[\"fold\"] = n_fold + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "        logging.info('Fold %2d val AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx])))\n",
    "\n",
    "        del clf, train_x, train_y, valid_x, valid_y\n",
    "        gc.collect()\n",
    "    logging.info('Over-folds train AUC score : {}'.format(roc_auc_score(train_df['TARGET'], train_preds)))\n",
    "    \n",
    "    over_folds_val_auc = roc_auc_score(train_df['TARGET'], oof_preds)\n",
    "    logging.info('Over-folds val AUC score : {}'.format(over_folds_val_auc))\n",
    "    \n",
    "    # # Write submission file and plot feature importance\n",
    "    # test_df.loc[:,'TARGET'] = sub_preds\n",
    "    # test_df[['SK_ID_CURR', 'TARGET']].to_csv(submission_file_name, index= False)\n",
    "\n",
    "    return feature_importance_df, over_folds_val_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    checked_already = ['base_featurs_filled_mice_by_cluster_2.h5', \n",
    "                   'base_featurs_filled_mice_by_cluster_2+1.h5',\n",
    "                  'base_featurs_filled_mice_by_cluster_1.h5',\n",
    "                  'base_featurs_filled_mice_half_training_data.h5',\n",
    "                  'base_featurs_filled_mice_clustering.h5']\n",
    "    for i in os.listdir('../features/filled_by_mice/'):\n",
    "        if 'target' in i:\n",
    "            if i == 'normalized_mice_discrete_w_peeking_target_612.h5': \n",
    "                #--------------------\n",
    "                # load features\n",
    "                #--------------------\n",
    "                df = pd.read_hdf('../features/filled_by_mice/{}'.format(i))\n",
    "                logging.info('loading features: {}'.format(i))\n",
    "                #--------------------\n",
    "                # out-of-fold validating stratigy + LGB\n",
    "                #--------------------    \n",
    "                with timer(\"Run LightGBM with kfold\"):\n",
    "                    feature_importance_df = pd.DataFrame()\n",
    "                    over_folds_val_auc_list = np.zeros(ITERATION)\n",
    "                    for i in range(ITERATION):\n",
    "                        logging.info('Iteration %i' %i)\n",
    "                        iter_feat_imp, over_folds_val_auc = kfold_lightgbm(df, num_folds= NUM_FOLDS, stratified= STRATIFIED)\n",
    "                        feature_importance_df = pd.concat([feature_importance_df, iter_feat_imp], axis=0)\n",
    "                        over_folds_val_auc_list[i] = over_folds_val_auc\n",
    "\n",
    "                    logging.info('Over-iterations val AUC score : {}'.format(over_folds_val_auc_list.mean()))\n",
    "                    logging.info('Standard deviation : {}'.format(over_folds_val_auc_list.std()))\n",
    "\n",
    "                    # display_importances(feature_importance_df)\n",
    "                    feature_importance_df_median = feature_importance_df[[\"feature\", \"importance\"]].groupby(\"feature\").median().sort_values(by=\"importance\", ascending=False)\n",
    "                    useless_features_df = feature_importance_df_median.loc[feature_importance_df_median['importance'] == 0]\n",
    "                    feature_importance_df_mean = feature_importance_df[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)\n",
    "                    #---------------------\n",
    "                    # save\n",
    "                    #---------------------\n",
    "                    output_path = '../output'\n",
    "                    if not os.path.isdir(output_path):\n",
    "                        os.mkdir(output_path)\n",
    "\n",
    "                    if TEST_NULL_HYPO:\n",
    "                        feature_importance_df_mean.to_csv(os.path.join(output_path, 'feature_importance-null_hypo.csv'), index = True)\n",
    "                    else:\n",
    "                        feature_importance_df_mean.to_csv(os.path.join(output_path, 'feature_importance.csv'), index = True)\n",
    "                        useless_features_list = useless_features_df.index.tolist()\n",
    "                        logging.info('useless/overfitting features: \\'' + '\\', \\''.join(useless_features_list) + '\\'')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized_mice_discrete_wo_target.h5\n",
      "normalized_mice_discrete_w_peeking_target_724.h5\n",
      "normalized_mice_discrete.h5\n",
      "normalized_mice_similar_features_th_09_5.h5\n",
      "normalized_mice_cluster_3.h5\n",
      "normalized_mice_discrete_w_peeking_target.h5\n",
      ".DS_Store\n",
      "normalized_mice_cluster_1_2_3.h5\n",
      "normalized_mice_similar_features_th_09_2.h5\n",
      "normalized_mice_similar_features_th_09_1.h5\n",
      "normalized_mice_cluster_2.h5\n",
      "normalized_mice_cluster_1.h5\n",
      "normalized_mice_discrete_w_peeking_target_612.h5\n",
      "base_featurs_filled_mice_half_training_data_wo_target.h5\n"
     ]
    }
   ],
   "source": [
    "checked_already = ['base_featurs_filled_mice_by_cluster_2.h5', \n",
    "                   'base_featurs_filled_mice_by_cluster_2+1.h5',\n",
    "                  'base_featurs_filled_mice_by_cluster_1.h5',\n",
    "                  'base_featurs_filled_mice_half_training_data.h5',\n",
    "                  'base_featurs_filled_mice_clustering.h5']\n",
    "for i in os.listdir('../features/filled_by_mice/'):\n",
    "    if i not in checked_already: \n",
    "            print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading features: normalized_mice_discrete_w_peeking_target_612.h5\n",
      "Iteration 0\n",
      "no bugging in split\n",
      "Starting LightGBM. Train shape: (307507, 280), test shape: (48744, 280)\n",
      "Fold  1 val AUC : 0.796300\n",
      "Fold  2 val AUC : 0.798675\n",
      "Fold  3 val AUC : 0.791667\n",
      "Fold  4 val AUC : 0.792033\n",
      "Fold  5 val AUC : 0.796188\n",
      "Over-folds train AUC score : 0.8754258688854542\n",
      "Over-folds val AUC score : 0.7949617620710923\n",
      "Iteration 1\n",
      "no bugging in split\n",
      "Starting LightGBM. Train shape: (307507, 280), test shape: (48744, 280)\n",
      "Fold  1 val AUC : 0.797527\n",
      "Fold  2 val AUC : 0.796904\n",
      "Fold  3 val AUC : 0.795919\n",
      "Fold  4 val AUC : 0.791305\n",
      "Fold  5 val AUC : 0.795934\n",
      "Over-folds train AUC score : 0.884716231654566\n",
      "Over-folds val AUC score : 0.7955004250645841\n",
      "Iteration 2\n",
      "no bugging in split\n",
      "Starting LightGBM. Train shape: (307507, 280), test shape: (48744, 280)\n",
      "Fold  1 val AUC : 0.799445\n",
      "Fold  2 val AUC : 0.796333\n",
      "Fold  3 val AUC : 0.793401\n",
      "Fold  4 val AUC : 0.791880\n",
      "Fold  5 val AUC : 0.800060\n",
      "Over-folds train AUC score : 0.8872853807529807\n",
      "Over-folds val AUC score : 0.7962065561726035\n",
      "Iteration 3\n",
      "no bugging in split\n",
      "Starting LightGBM. Train shape: (307507, 280), test shape: (48744, 280)\n",
      "Fold  1 val AUC : 0.794731\n",
      "Fold  2 val AUC : 0.796647\n",
      "Fold  3 val AUC : 0.793220\n",
      "Fold  4 val AUC : 0.799827\n",
      "Fold  5 val AUC : 0.794833\n",
      "Over-folds train AUC score : 0.8827163251768257\n",
      "Over-folds val AUC score : 0.7958273420056811\n",
      "Iteration 4\n",
      "no bugging in split\n",
      "Starting LightGBM. Train shape: (307507, 280), test shape: (48744, 280)\n",
      "Fold  1 val AUC : 0.792449\n",
      "Fold  2 val AUC : 0.793796\n",
      "Fold  3 val AUC : 0.799313\n",
      "Fold  4 val AUC : 0.798185\n",
      "Fold  5 val AUC : 0.796765\n",
      "Over-folds train AUC score : 0.8839115568981739\n",
      "Over-folds val AUC score : 0.7960928524562094\n",
      "Iteration 5\n",
      "no bugging in split\n",
      "Starting LightGBM. Train shape: (307507, 280), test shape: (48744, 280)\n",
      "Fold  1 val AUC : 0.798006\n",
      "Fold  2 val AUC : 0.797763\n",
      "Fold  3 val AUC : 0.787520\n",
      "Fold  4 val AUC : 0.796170\n",
      "Fold  5 val AUC : 0.799741\n",
      "Over-folds train AUC score : 0.8884938879897305\n",
      "Over-folds val AUC score : 0.795813293146834\n",
      "Iteration 6\n",
      "no bugging in split\n",
      "Starting LightGBM. Train shape: (307507, 280), test shape: (48744, 280)\n",
      "Fold  1 val AUC : 0.796085\n",
      "Fold  2 val AUC : 0.792990\n",
      "Fold  3 val AUC : 0.794738\n",
      "Fold  4 val AUC : 0.798676\n",
      "Fold  5 val AUC : 0.796922\n",
      "Over-folds train AUC score : 0.8828498094995174\n",
      "Over-folds val AUC score : 0.7958744005314708\n",
      "Iteration 7\n",
      "no bugging in split\n",
      "Starting LightGBM. Train shape: (307507, 280), test shape: (48744, 280)\n",
      "Fold  1 val AUC : 0.797646\n",
      "Fold  2 val AUC : 0.797278\n",
      "Fold  3 val AUC : 0.796983\n",
      "Fold  4 val AUC : 0.796313\n",
      "Fold  5 val AUC : 0.792573\n",
      "Over-folds train AUC score : 0.8783689052437181\n",
      "Over-folds val AUC score : 0.7961371329590633\n",
      "Iteration 8\n",
      "no bugging in split\n",
      "Starting LightGBM. Train shape: (307507, 280), test shape: (48744, 280)\n",
      "Fold  1 val AUC : 0.795003\n",
      "Fold  2 val AUC : 0.794489\n",
      "Fold  3 val AUC : 0.797742\n",
      "Fold  4 val AUC : 0.798108\n",
      "Fold  5 val AUC : 0.794012\n",
      "Over-folds train AUC score : 0.8861462556899862\n",
      "Over-folds val AUC score : 0.7958343677888475\n",
      "Iteration 9\n",
      "no bugging in split\n",
      "Starting LightGBM. Train shape: (307507, 280), test shape: (48744, 280)\n",
      "Fold  1 val AUC : 0.792941\n",
      "Fold  2 val AUC : 0.798521\n",
      "Fold  3 val AUC : 0.794777\n",
      "Fold  4 val AUC : 0.800897\n",
      "Fold  5 val AUC : 0.791499\n",
      "Over-folds train AUC score : 0.880402056797167\n",
      "Over-folds val AUC score : 0.7957162819354274\n",
      "Over-iterations val AUC score : 0.7957964414131814\n",
      "Standard deviation : 0.0003422893568343621\n",
      "useless/overfitting features: 'ORGANIZATION_TYPE_Restaurant', 'OCCUPATION_TYPE_Core staff', 'OCCUPATION_TYPE_Accountants', 'OCCUPATION_TYPE_Low-skill Laborers', 'OCCUPATION_TYPE_Medicine staff', 'OCCUPATION_TYPE_Sales staff'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run LightGBM with kfold - done in 6382s\n",
      "Lightgbm run a score - done in 6383s\n"
     ]
    }
   ],
   "source": [
    "CPU_USE_RATE = 0.4\n",
    "log_dir = '../log_imputating_exp' # +了11個補完值得new feautures的實驗..\n",
    "init_logging(log_dir)\n",
    "with timer(\"Lightgbm run a score\"):\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# why overefit? 思考一下\n",
    "\n",
    "# 加一條標準差的虛線...\n",
    "0.7959379558537741 - 0.0003017394118141831 > 0.795883003439369 #(0.7962306295343666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('../py_model/sub.csv')\n",
    "sub.drop(['Unnamed: 0'], axis = 1 , inplace = True)\n",
    "sub.SK_ID_CURR = sub.SK_ID_CURR.map(lambda x: str(int(x)))\n",
    "sub.to_csv('../py_model/sub.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(0.05, 0.01, step = - 0.01):\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
